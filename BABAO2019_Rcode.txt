#install required packages if necessary
install.packages(c("ggplot2", "harrypotter", "devtools"))
devtools::install_github("bbartholdy/BAMSAUR")

library(BAMSAUR)
library(ggplot2)
library(harrypotter)

#The functions for simulation, accuracy calculation, and generating plots, respectively.
sim <- function(age, n, out){
  clas <- function(age, wear){
    y <- MBsimple$Wear
    x <- MBsimple$Age
    model <- lm(y ~ x)
    intercept <- model$coefficients[[1]]
    a <- model$coefficients[[2]]
    age_est <- (wear - intercept)/a
    invisible(list("age" = age, "estimate" = age_est))
   }
  inv <- function(age, wear){
    #inverse calibration
    n <- as.numeric(length(age))
    age_est <- suppressWarnings(BAMSAUR(wear, rank = 1))
    invisible(list("age" = age, "estimate" = age_est))
   }
  
  newdata <- age[sample(1:length(age), n, replace = T)]
  #remove generated ages below 0
  newdata[newdata < 0] <- NA
  newdata[newdata > 20] <- NA
  newdata <- na.omit(newdata)
  age <- newdata
  error <- rnorm(length(age), 0, 1)  
  slope <- rnorm(1, 0.64, 0.05)
  wear <- age*slope + 1 + error
  data <- as.data.frame(cbind(age, wear))
  colnames(data) <- c("age", "wear")
#classical calibration 
  clas <- clas(age, wear)
  est_clas <- round(clas$estimate, 1)
  clas_diff <- clas$age - clas$estimate
#inverse calibration
  inv <- inv(age, wear)
  est_inv <- round(inv$estimate[,2], 1)
  inv_diff <- inv$age - inv$estimate[,2]
#output
  age <- round(age, 1)
  RSS_clas <- sum(clas_diff^2)
  RSS_inv <- sum(inv_diff^2)
  est <- cbind(age, est_clas, clas_diff, RSS_clas, est_inv, inv_diff, RSS_inv)
  out <- est
  colnames(out) <- c("age", "est_clas", "clas_diff", "clas_RSS", "est_inv", "inv_diff", "inv_RSS")
  return(out)
}
acc <- function(clas_diff, inv_diff){
  clas_diff <- abs(df$clas_diff)
  is.true.2 <- (clas_diff < 2 | clas_diff == 2)
  is.true.3 <- (clas_diff < 3 | clas_diff == 3)
  is.true.4 <- (clas_diff < 4 | clas_diff == 4)
  is.true.2 <- as.numeric(is.true.2)
  is.true.3 <- as.numeric(is.true.3)
  is.true.4 <- as.numeric(is.true.4)
  accuracy.2 <- mean(is.true.2) * 100
  accuracy.3 <- mean(is.true.3) * 100
  accuracy.4 <- mean(is.true.4) * 100
  clas_acc <- cbind(accuracy.2, accuracy.3)
  
  inv_diff <- abs(df$inv_diff)
  is.true.2 <- (inv_diff < 2 | inv_diff == 2)
  is.true.3 <- (inv_diff < 3 | inv_diff == 3)
  is.true.4 <- (inv_diff < 4 | inv_diff == 4)
  is.true.2 <- as.numeric(is.true.2)
  is.true.3 <- as.numeric(is.true.3)
  is.true.4 <- as.numeric(is.true.4)
  accuracy.2 <- mean(is.true.2) * 100
  accuracy.3 <- mean(is.true.3) * 100
  accuracy.4 <- mean(is.true.4) * 100
  inv_acc <- cbind(accuracy.2, accuracy.3)
  out <- cbind(clas_acc, inv_acc)
  colnames(out) <- c("clas.acc_2", "clas.acc_3", "inv.acc_2", "inv.acc_3") 
  return(out)
}
sim.plot <- function(age, est_cla, est_inv, house = "Hufflepuff"){
  MB_factor <- as.data.frame(cbind(MBsimple$Age, rep("MB11", length(MBsimple$Age))))
  colnames(MB_factor) <- c("age", "sample")
  age_factor <- as.data.frame(cbind(age, rep("known",length(age))))
  colnames(age_factor) <- c("age", "sample")
  inv_factor <- as.data.frame(cbind(est_inv, rep("inverse",length(est_inv))))
  colnames(inv_factor) <- c("age", "sample")
  clas_factor <- as.data.frame(cbind(est_cla, rep("classical",length(est_cla))))
  colnames(clas_factor) <- c("age", "sample")
  pl.data <- as.data.frame(rbind(age_factor, inv_factor, clas_factor, MB_factor))
  pl.data$age <- as.numeric(levels(pl.data$age))[pl.data$age]
  pl <- ggplot(pl.data, aes(x = age, fill = sample)) +
    geom_histogram(aes(y = ..density..),binwidth = 1.5, color = "grey30") +
    facet_grid(sample ~ .) + scale_fill_hp(discrete = T, option = house) + 
    theme(legend.position = "none", axis.title.x = element_blank(), axis.title.y = element_blank())
  print(pl)
}

#Step 1
#Age-at-death samples generated with a sample size of 10000
#Each distribution should be run separately, i.e. complete step 1 for the first distribution and continue to steps 2 and 3,
#then go back to step 1 for the uniform distribution and complete steps 1 and 3 for uniform, etc.

#Normal distribution
dist <- "norm"
mu <- 10
set.seed(1)
age <- rnorm(10000, mean = mu, sd = 3)
house <- "Gryffindor"

#Uniform distribution
dist <- "unif"
min.unif <- 0
max.unif <- 20
set.seed(2)
age <- runif(10000, min = min.unif, max = max.unif)
house <- "Slytherin"

#Negative skewed distribution
dist <- "skew.R"
set.seed(4)
age <- rgamma(10000, scale = 1, shape = 8)
house <- "Hufflepuff"

#Positive skewed distribution
dist <- "skew.L"
age <- rgamma(10000, scale = 1, shape = 8)
age <- max(age) - age
set.seed(4)
house <- "Ravenclaw"

#Step 2
#Simulation of 100 randomly drawn individuals (n) run with 1000 iterations (n1)
n <- 100
n1 <- 1000
est <- replicate(n1, sim(age, n, out = "estimate"), simplify = F)
df <- as.data.frame(do.call(rbind, est))
colnames(df) <- c("age", "clas_est", "clas_diff", "clas_RSS", "inv_est", "inv_diff", "inv_RSS")
colMeans(df) #This will show the mean for known ages-at-death, predictions and residual sum of squares from both methods for the 1000 iterations
c(median(df$age), median(df$clas_est), median(df$inv_est)) #This will show the median for known ages-at-death, and the predicted median for both methods.  
acc(df$clas_diff, df$inv_diff) #This will calculate the accuracy of both methods

#Step 3
#Generate plots
#Age-at-death distribution
sim.plot(df$age, df$clas_est, df$inv_est, house = house)

#Residuals vs age-at-death for the classical calibration
lm_clas <- lm(clas_diff ~ age, df)
smoothScatter(df$age, df$clas_diff, ylab = "residuals", xlab = "age-at-death", ylim = c(-10,10))
abline(0,0, lwd = 1)
abline(lm_clas$coefficients[[1]],lm_clas$coefficients[[2]], lwd = 2, lty = "dashed")

#Residuals vs age-at-death for the inverse calibration
lm_inv <- lm(inv_diff ~ age, df)
smoothScatter(df$age, df$inv_diff, xlab = "age", ylab = "residuals")
abline(0,0, lwd = 1)
abline(lm_inv$coefficients[[1]],lm_inv$coefficients[[2]], lwd = 2, lty = "dashed")
abline(lm_clas$coefficients[[1]],lm_clas$coefficients[[2]], lwd = 2, lty = "dashed", col = "red")
#Test for correlation between residuals and age-at-death for both methods
#The higher the correlation coefficient, the larger the bias
cor(df$age, df$clas_diff)
cor(df$age, df$inv_diff)